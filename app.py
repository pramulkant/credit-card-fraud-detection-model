import streamlit as st
import pandas as pd
import pickle
import os
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Page configuration
st.set_page_config(page_title="Credit Card Fraud Detector", layout="wide")

st.title("üõ°Ô∏è Credit Card Fraud Detection Dashboard")
st.markdown("""
This application allows you to upload transaction data and use various Machine Learning models 
to identify potentially fraudulent activities.
""")

# Sidebar for Model Selection [cite: 92]
st.sidebar.header("Settings")
model_option = st.sidebar.selectbox(
    "Select ML Model",
    ("Logistic Regression", "Decision Tree", "KNN", "Naive Bayes", "Random Forest", "XGBoost")
)

# Feature: Dataset upload (CSV) [cite: 91]
st.subheader("1. Upload Test Data")
uploaded_file = st.file_uploader("Choose a CSV file containing transaction data", type="csv")

if uploaded_file is not None:
    # Load the data
    test_df = pd.read_csv(uploaded_file)
    st.write("### Data Preview")
    st.dataframe(test_df.head())

    # Check for required target column 'Class'
    if 'Class' not in test_df.columns:
        st.error("Error: The uploaded CSV must contain a 'Class' column for evaluation.")
    else:
        # Load the pre-trained model 
        # Filenames follow the pattern generated by the training script
        model_filename = f"model/{model_option.replace(' ', '_').lower()}.pkl"
        
        if not os.path.exists(model_filename):
            st.warning(f"Model file '{model_filename}' not found. Please ensure your models are saved in the 'model/' folder.")
        else:
            with open(model_filename, 'rb') as f:
                model = pickle.load(f)

            # Features and Target
            X_test = test_df.drop('Class', axis=1)
            y_test = test_df['Class']

            # Predict
            y_pred = model.predict(X_test)

            # Feature: Display Evaluation Metrics [cite: 93]
            st.subheader(f"2. Evaluation Metrics: {model_option}")
            
            # Use classification_report for detailed metrics
            report = classification_report(y_test, y_pred, output_dict=True)
            report_df = pd.DataFrame(report).transpose()
            
            col1, col2, col3 = st.columns(3)
            col1.metric("Accuracy", f"{report['accuracy']:.4f}")
            col2.metric("Macro F1-Score", f"{report['macro avg']['f1-score']:.4f}")
            col3.metric("Weighted Recall", f"{report['weighted avg']['recall']:.4f}")

            st.write("Detailed Classification Report:")
            st.dataframe(report_df)

            # Feature: Confusion Matrix [cite: 94]
            st.subheader("3. Visualization")
            st.write("Confusion Matrix:")
            cm = confusion_matrix(y_test, y_pred)
            
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', 
                        xticklabels=['Genuine', 'Fraud'], 
                        yticklabels=['Genuine', 'Fraud'])
            plt.ylabel('Actual')
            plt.xlabel('Predicted')
            st.pyplot(fig)

else:
    st.info("Please upload a CSV file to get started.")
    st.markdown("""
    **Note for Evaluation:** As per assignment requirements, please upload only **test data** to ensure the app 
    loads quickly within Streamlit's free tier capacity. [cite: 91]
    """)